#!/bin/bash

# === Usage ===
if [ "$#" -ne 4 ]; then
  echo "Usage: $0 input.csv CODEHASH JOB_REFERENCE RUN_TYPE"
  exit 1
fi

CSV_FILE="$1"
CODEHASH="$2"
JOB_REFERENCE="$3"
RUN_TYPE="$4"

if [ ! -f "$CSV_FILE" ]; then
  echo "CSV file not found: $CSV_FILE"
  exit 1
fi

# === Config ===
# Make sure these environment variables are set or export here
# export GCP_PROJECT_ID="your-project"
# export GCP_INSTANCE_ID="your-instance"
# export GCP_DATABASE_ID="your-database"

# === Read CSV and skip header ===
tail -n +2 "$CSV_FILE" | while IFS=',' read -r DEVICE MODEL MAX_NUM_SEQS MAX_NUM_BATCHED_TOKENS TENSOR_PARALLEL_SIZE MAX_MODEL_LEN DATASET INPUT_LEN OUTPUT_LEN
do
  RECORD_ID=$(uuidgen | tr 'A-Z' 'a-z')

  # calculate the queue name from the device
  QUEUE_TOPIC="vllm-bm-queue-$DEVICE"

  # Check if the topic exists
  if ! gcloud pubsub topics describe "$QUEUE_TOPIC" --project="$GCP_PROJECT_ID" &>/dev/null; then
    echo "Topic '$QUEUE_TOPIC' does not exist in $GCP_PROJECT_ID."
    echo "Skip creating record in RunRecord table."
    continue
  fi

  echo "Inserting RecordId: $RECORD_ID"
  gcloud spanner databases execute-sql "$GCP_DATABASE_ID" \
    --instance="$GCP_INSTANCE_ID" \
    --project="$GCP_PROJECT_ID" \
    --sql="INSERT INTO RunRecord (
      RecordId, Status, CreatedTime, Device, Model, RunType, CodeHash,
      MaxNumSeqs, MaxNumBatchedTokens, TensorParallelSize, MaxModelLen,
      Dataset, InputLen, OutputLen, LastUpdate, CreatedBy,JobReference
    ) VALUES (
      '$RECORD_ID', 'CREATED', PENDING_COMMIT_TIMESTAMP(), '$DEVICE', '$MODEL', '$RUN_TYPE', '$CODEHASH',
      $MAX_NUM_SEQS, $MAX_NUM_BATCHED_TOKENS, $TENSOR_PARALLEL_SIZE, $MAX_MODEL_LEN,
      '$DATASET', $INPUT_LEN, $OUTPUT_LEN, PENDING_COMMIT_TIMESTAMP(), '$USER', '$JOB_REFERENCE'
    );"  

  echo "Publishing to Pub/Sub queue: $GCP_QUEUE"
  # Construct key-value string
  MESSAGE_BODY="RecordId=$RECORD_ID"
  # Publish the message
  gcloud pubsub topics publish $QUEUE_TOPIC \
    --project="$GCP_PROJECT_ID" \
    --message="$MESSAGE_BODY"
done